\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{â‚¬}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={Justin Le},
            pdftitle={You Could Have Invented Matrices!},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
% Make links footnotes instead of hotlinks:
\renewcommand{\href}[2]{#2\footnote{\url{#1}}}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}

\title{You Could Have Invented Matrices!}
\author{Justin Le}

\begin{document}
\maketitle

\emph{Originally posted on
\textbf{\href{https://blog.jle.im/entry/you-could-have-invented-matrices.html}{in
Code}}.}

You could have invented matrices!

Let's talk about vectors. A \textbf{vector} (denoted as
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbf\%7Bv\%7D}, a
lower-case bold italicized letter) is an element in a \textbf{vector space},
which means that it can be ``scaled'', like
\includegraphics{https://latex.codecogs.com/png.latex?c\%20\%5Cmathbf\%7Bv\%7D}
(the \includegraphics{https://latex.codecogs.com/png.latex?c} is called a
``scalar'' --- creative name, right?) and added, like
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbf\%7Bv\%7D\%20\%2B\%20\%5Cmathbf\%7Bu\%7D}.

In order for vector spaces and their operations to be valid, they just have to
obey some common-sense rules (like associativity, commutativity, distributivity,
etc.) that allow us to make meaningful conclusions.\footnote{In short, vector
  spaces form an Abelian group (which is another way of just saying that
  addition is commutative, associative, has an identity, and an inverse), and
  scalars have to play nice with addition
  (\includegraphics{https://latex.codecogs.com/png.latex?c\%28\%5Cmathbf\%7Bv\%7D\%20\%2B\%20\%5Cmathbf\%7Bu\%7D\%29\%20\%3D\%20c\%20\%5Cmathbf\%7Bv\%7D\%20\%2B\%20c\%20\%5Cmathbf\%7Bu\%7D},
  and
  \includegraphics{https://latex.codecogs.com/png.latex?\%28c\%20\%2B\%20d\%29\%5Cmathbf\%7Bv\%7D\%20\%3D\%20c\%20\%5Cmathbf\%7Bv\%7D\%20\%2B\%20d\%20\%5Cmathbf\%7Bv\%7D}).
  Also, scalars themselves form a field.}

\hypertarget{dimensionality}{%
\section{Dimensionality}\label{dimensionality}}

One neat thing about vector spaces is that \emph{some} of them (if you're lucky)
have a notion of \textbf{dimensionality}. We say that a vector space is
N-dimensional if there exists N ``basis'' vectors
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbf\%7Be\%7D_1\%2C\%20\%5Cmathbf\%7Be\%7D_2\%20\%5Cldots\%20\%5Cmathbf\%7Be\%7D_N}
where \emph{any} vector can be described as scaled sums of all of them, and that
N is the lowest number of basis vectors needed. For example, if a vector space
is 3-dimensional, then it means that \emph{any} vector
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbf\%7Bv\%7D} in
that space can be broken down as:

{[} \textbackslash{}mathbf\{v\} = a \textbackslash{}mathbf\{e\}\_1 + b
\textbackslash{}mathbf\{e\}\_2 + c
\textbackslash{}mathbf\{e\}\_3{]}(https://latex.codecogs.com/png.latex?\%0A\%5Cmathbf\%7Bv\%7D\%20\%3D\%20a\%20\%5Cmathbf\%7Be\%7D\_1\%20\%2B\%20b\%20\%5Cmathbf\%7Be\%7D\_2\%20\%2B\%20c\%20\%5Cmathbf\%7Be\%7D\_3\%0A
" \mathbf{v} = a \mathbf{e}\_1 + b \mathbf{e}\_2 + c \mathbf{e}\_3 ``)

Where \includegraphics{https://latex.codecogs.com/png.latex?a},
\includegraphics{https://latex.codecogs.com/png.latex?b}, and
\includegraphics{https://latex.codecogs.com/png.latex?c} are scalars.

Dimensionality is really a statement about being able to decompose any vector in
that vector space into a useful set of bases. For a 3-dimensional vector space,
you need at least 3 vectors to make a bases that can reproduce \emph{any} vector
in your space.

In physics, we often treat reality as taking place in a three-dimensional vector
space. The basis vectors are often called
\includegraphics{https://latex.codecogs.com/png.latex?\%5Chat\%7B\%5Cmathbf\%7Bi\%7D\%7D},
\includegraphics{https://latex.codecogs.com/png.latex?\%5Chat\%7B\%5Cmathbf\%7Bj\%7D\%7D},
and
\includegraphics{https://latex.codecogs.com/png.latex?\%5Chat\%7B\%5Cmathbf\%7Bk\%7D\%7D},
and so we say that we can describe our 3D physics vectors as
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbf\%7Bv\%7D\%20\%3D\%20v_x\%20\%5Chat\%7B\%5Cmathbf\%7Bi\%7D\%7D\%20\%2B\%20v_y\%20\%5Chat\%7B\%5Cmathbf\%7Bj\%7D\%7D\%20\%2B\%20v_x\%20\%5Chat\%7B\%5Cmathbf\%7Bk\%7D\%7D}

\hypertarget{encoding}{%
\subsection{Encoding}\label{encoding}}

One neat thing that physicists take advantage of all the time is that if we
\emph{agree} on a set of basis vectors and a specific ordering, we can actually
\emph{encode} any vector
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbf\%7Bv\%7D} in
terms of those basis vectors.

So in physics, we can say ``Let's encode vectors in terms of
\includegraphics{https://latex.codecogs.com/png.latex?\%5Chat\%7B\%5Cmathbf\%7Bi\%7D\%7D},
\includegraphics{https://latex.codecogs.com/png.latex?\%5Chat\%7B\%5Cmathbf\%7Bj\%7D\%7D},
and
\includegraphics{https://latex.codecogs.com/png.latex?\%5Chat\%7B\%5Cmathbf\%7Bk\%7D\%7D},
in that order.'' Then, we can \emph{write}
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbf\%7Bv\%7D} as
\includegraphics{https://latex.codecogs.com/png.latex?\%5Clangle\%20v_x\%2C\%20v_y\%2C\%20v_z\%20\%5Crangle},
and understand that we really
mean\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbf\%7Bv\%7D\%20\%3D\%20v_x\%20\%5Chat\%7B\%5Cmathbf\%7Bi\%7D\%7D\%20\%2B\%20v_y\%20\%5Chat\%7B\%5Cmathbf\%7Bj\%7D\%7D\%20\%2B\%20v_x\%20\%5Chat\%7B\%5Cmathbf\%7Bk\%7D\%7D}.

Note that
\includegraphics{https://latex.codecogs.com/png.latex?\%5Clangle\%20v_x\%2C\%20v_y\%2C\%20v_z\%20\%5Crangle}
is \textbf{not} the same thing as the \textbf{vector}
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbf\%7Bv\%7D}. It
is \emph{an encoding} of that vector, that only makes sense once we choose to
\emph{agree} on a specific set of basis.

For an N-dimensional vector space, it means that, with a minimum of N items, we
can represent any vector in that space. And, if we agree on those N items, we
can devise an encoding, such that:

{[} \textbackslash{}langle v\_1, v\_2 \textbackslash{}dots v\_N
\textbackslash{}rangle{]}(https://latex.codecogs.com/png.latex?\%0A\%5Clangle\%20v\_1\%2C\%20v\_2\%20\%5Cdots\%20v\_N\%20\%5Crangle\%0A
" \langle v\_1, v\_2 \dots v\_N \rangle ``)

will \emph{represent} the vector:

{[} v\_1 \textbackslash{}mathbf\{e\}\_1 + v\_2 \textbackslash{}mathbf\{e\}\_2 +
\textbackslash{}ldots + v\_N
\textbackslash{}mathbf\{e\}\_N{]}(https://latex.codecogs.com/png.latex?\%0Av\_1\%20\%5Cmathbf\%7Be\%7D\_1\%20\%2B\%20v\_2\%20\%5Cmathbf\%7Be\%7D\_2\%20\%2B\%20\%5Cldots\%20\%2B\%20v\_N\%20\%5Cmathbf\%7Be\%7D\_N\%0A
" v\_1 \mathbf{e}\_1 + v\_2 \mathbf{e}\_2 + \ldots + v\_N \mathbf{e}\_N ``)

Note that what this encoding represents is \emph{completely dependent} on what
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbf\%7Be\%7D_1\%2C\%20\%5Cmathbf\%7Be\%7D_2\%20\%5Cldots\%20\%5Cmathbf\%7Be\%7D_N}
we pick, and in what order. The basis vectors we pick are arbitrary, and
determine what our encoding looks like.

To highlight this, note that the same vector
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbf\%7Bv\%7D} has
many different potential encodings --- all you have to do is pick a different
set of basis vectors, or even just re-arrange the ones you already have.
However, all of those encodings correspond go the same vector
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbf\%7Bv\%7D}.

One interesting consequence of this is that any N-dimensional vector space whose
scalars are in
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbb\%7BR\%7D} is
actually isomorphic to
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbf\%7BR\%7D\%5EN}
--- the vector space of N-tuples of real numbers. Because of this, we often call
\emph{all} N-dimensional vector spaces (whose scalars are in
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbb\%7BR\%7D}) as
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbb\%7BR\%7D\%5EN}.
You will often hear physicists saying that the three-dimensional vector spaces
they use are
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbb\%7BR\%7D\%5E3}.
However, what they really mean is that their vectors are isomorphic to
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cmathbb\%7BR\%7D\%5E3}.

\hypertarget{linear-transformations}{%
\section{Linear Transformations}\label{linear-transformations}}

Now, one of the most interesting things in mathematics is the idea of the
\textbf{linear transformation}. Linear transformations are useful to study
because:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  They are ubiquitious. They either come up everywhere in engineering, physics,
  mathematics, data science, economics, and pretty much any mathematical theory.
  And there are even more situations which can be \emph{approximated} by linear
  transformations.
\item
  They are mathematically very nice to work with and study, in practice.
\end{enumerate}

A linear transformation,
\includegraphics{https://latex.codecogs.com/png.latex?A\%28\%5Cmathbf\%7Bx\%7D\%29},
is a function that respects `addition' and `scaling':

{[} \textbackslash{}begin\{aligned\} A(c\textbackslash{}mathbf\{x\}) \& = c
A(\textbackslash{}mathbf\{x\}) \textbackslash{}\textbackslash{}
A(\textbackslash{}mathbf\{x\} + \textbackslash{}mathbf\{y\}) =
A(\textbackslash{}mathbf\{x\}) + A (\textbackslash{}mathbf\{y\})
\textbackslash{}end\{aligned\}{]}(https://latex.codecogs.com/png.latex?\%0A\%5Cbegin\%7Baligned\%7D\%0AA\%28c\%5Cmathbf\%7Bx\%7D\%29\%20\%26\%20\%3D\%20c\%20A\%28\%5Cmathbf\%7Bx\%7D\%29\%20\%5C\%5C\%0AA\%28\%5Cmathbf\%7Bx\%7D\%20\%2B\%20\%5Cmathbf\%7By\%7D\%29\%20\%3D\%20A\%28\%5Cmathbf\%7Bx\%7D\%29\%20\%2B\%20A\%20\%28\%5Cmathbf\%7By\%7D\%29\%0A\%5Cend\%7Baligned\%7D\%0A
"

\begin{aligned}
A(c\mathbf{x}) & = c A(\mathbf{x}) \\
A(\mathbf{x} + \mathbf{y}) = A(\mathbf{x}) + A (\mathbf{y})
\end{aligned}

``)

This means that if you scale the input, the output is scaled by the same amount.
And also, if you transform the sum of two things, it's the same as the sum of
the transformed things (it ``distributes'').

Note that I snuck in vector notation, because the concept of vectors are
\emph{perfectly suited} for studying linear transformations. That's because
talking about linear transformations requires talking about scaling and adding,
and\ldots{}hey, that's just exactly what vectors have!

In the study of linear transformations, it might be useful to write the function
\includegraphics{https://latex.codecogs.com/png.latex?A\%28\%5Cmathbf\%7Bx\%7D\%29}
in \emph{operator notation},
\includegraphics{https://latex.codecogs.com/png.latex?\%5Chat\%7BA\%7D\%20\%5Cmathbf\%7Bx\%7D},
which is read as ``the operator
\includegraphics{https://latex.codecogs.com/png.latex?\%5Chat\%7BA\%7D} applied
to \mathbf{x}''. This makes our description of linear transformations look a
little nicer:

{[} \textbackslash{}begin\{aligned\}
\textbackslash{}hat\{A\}(c\textbackslash{}mathbf\{x\}) \& =
c(\textbackslash{}hat\{A\}\textbackslash{}mathbf\{x\})
\textbackslash{}\textbackslash{}
\textbackslash{}hat\{A\}(\textbackslash{}mathbf\{x\} +
\textbackslash{}mathbf\{y\}) = \textbackslash{}hat\{A\}
\textbackslash{}mathbf\{x\} + \textbackslash{}hat\{A\}
\textbackslash{}mathbf\{y\}
\textbackslash{}end\{aligned\}{]}(https://latex.codecogs.com/png.latex?\%0A\%5Cbegin\%7Baligned\%7D\%0A\%5Chat\%7BA\%7D\%28c\%5Cmathbf\%7Bx\%7D\%29\%20\%26\%20\%3D\%20c\%28\%5Chat\%7BA\%7D\%5Cmathbf\%7Bx\%7D\%29\%20\%5C\%5C\%0A\%5Chat\%7BA\%7D\%28\%5Cmathbf\%7Bx\%7D\%20\%2B\%20\%5Cmathbf\%7By\%7D\%29\%20\%3D\%20\%5Chat\%7BA\%7D\%20\%5Cmathbf\%7Bx\%7D\%20\%2B\%20\%5Chat\%7BA\%7D\%20\%5Cmathbf\%7By\%7D\%0A\%5Cend\%7Baligned\%7D\%0A
"

\begin{aligned}
\hat{A}(c\mathbf{x}) & = c(\hat{A}\mathbf{x}) \\
\hat{A}(\mathbf{x} + \mathbf{y}) = \hat{A} \mathbf{x} + \hat{A} \mathbf{y}
\end{aligned}

``)

This makes the requirements look visually like the associativity and
distributivity of multiplication and addition. Really, though, this is nothing
more than a cheap trick.

\end{document}
